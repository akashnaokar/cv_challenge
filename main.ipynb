{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From f:\\Coding\\cv_challenge\\.venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import IPython.display as display\n",
    "from tensorflow import data as tf_data\n",
    "\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Conv2D , MaxPooling2D, Flatten, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import xml.etree.cElementTree as et\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Unzipping data set to a local director  \"\"\"\n",
    "\n",
    "from zipfile import ZipFile\n",
    "\n",
    "with ZipFile(\"F:\\\\Coding\\\\cv_challenge\\\\archive.zip\", 'r') as Dataset:\n",
    "    Dataset.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 : Convert image data into TFRecordDataset format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "  if isinstance(value, type(tf.constant(0))):\n",
    "    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = ('F:\\\\Coding\\\\cv_challenge\\\\NEU-DET')\n",
    "train_folder_path = os.path.join(data_folder, \"train\", )\n",
    "valid_folder_path = os.path.join(data_folder, \"validation\", )\n",
    "\n",
    "def create_img_list(folder_path):\n",
    "    image_list = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.jpg'):\n",
    "                image_path = os.path.join(root, file)\n",
    "                image_list.append(image_path)\n",
    "\n",
    "    return image_list\n",
    "\n",
    "train_img_list = create_img_list(train_folder_path)\n",
    "valid_img_list = create_img_list(valid_folder_path)\n",
    "\n",
    "\n",
    "train_anno_path = os.path.join(data_folder,\"train\", \"annotations\")\n",
    "train_anno_files_list = os.listdir(train_anno_path)\n",
    "valid_anno_path = os.path.join(data_folder,\"validation\", \"annotations\")\n",
    "valid_anno_files_list = os.listdir(valid_anno_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Extracting Lables from XML files \"\"\"\n",
    "\n",
    "def parseXML(xmlfile):\n",
    "    # create element tree object \n",
    "    tree = et.parse(xmlfile)  \n",
    "    # get root element \n",
    "    root = tree.getroot()\n",
    "\n",
    "    data = {}\n",
    "    data['filename'] = root.find('filename').text\n",
    "\n",
    "    size = root.find('size')\n",
    "    data['size'] = {\n",
    "        'width': int(size.find('width').text),\n",
    "        'height': int(size.find('height').text),\n",
    "        'depth': int(size.find('depth').text)\n",
    "    }\n",
    "    \n",
    "    obj = root.find('object')\n",
    "    data['object'] = {\n",
    "        'name': obj.find('name').text,\n",
    "        'pose': obj.find('pose').text,\n",
    "        'truncated': int(obj.find('truncated').text),\n",
    "        'difficult': int(obj.find('difficult').text),\n",
    "        'bndbox': {\n",
    "            'xmin': int(obj.find('bndbox/xmin').text),\n",
    "            'ymin': int(obj.find('bndbox/ymin').text),\n",
    "            'xmax': int(obj.find('bndbox/xmax').text),\n",
    "            'ymax': int(obj.find('bndbox/ymax').text)\n",
    "        }\n",
    "    }\n",
    "    # objects = []\n",
    "    # for obj in root.findall('object'):\n",
    "    #     obj_data = {\n",
    "    #         'name': obj.find('name').text,\n",
    "    #         'pose': obj.find('pose').text,\n",
    "    #         'truncated': int(obj.find('truncated').text),\n",
    "    #         'difficult': int(obj.find('difficult').text),\n",
    "    #         'bndbox': {\n",
    "    #             'xmin': int(obj.find('bndbox/xmin').text),\n",
    "    #             'ymin': int(obj.find('bndbox/ymin').text),\n",
    "    #             'xmax': int(obj.find('bndbox/xmax').text),\n",
    "    #             'ymax': int(obj.find('bndbox/ymax').text)\n",
    "    #         }\n",
    "    #     }\n",
    "    #     objects.append(obj_data)\n",
    "\n",
    "    # data['objects'] = objects\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['crazing', 'inclusion', 'patches', 'pitted_surface', 'rolled-in_scale', 'scratches']\n",
      "{'crazing': 0, 'inclusion': 1, 'patches': 2, 'pitted_surface': 3, 'rolled-in_scale': 4, 'scratches': 5}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Get distinct class labels from xml files\n",
    "Returns a list of distinct labels\n",
    "\"\"\"\n",
    "\n",
    "labels = []\n",
    "for anno in train_anno_files_list:\n",
    "    attr = parseXML(train_anno_path +\"\\\\\"+anno)\n",
    "    label = attr[\"object\"][\"name\"]\n",
    "    if label not in labels:\n",
    "        labels.append(label)\n",
    "print(labels)\n",
    "\n",
    "\"\"\"\n",
    "Assigning distinct values to each distinct label\n",
    "\"\"\"\n",
    "image_labels = {name: index for index, name in enumerate(labels)}\n",
    "n_class = len(image_labels)\n",
    "print(image_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_example(image_string, width, height, filename, xmin, xmax, ymin, ymax, label, label_text):\n",
    "  # print('w & h',width, height)\n",
    "  feature = {\n",
    "        \"image/width\": _int64_feature(width),\n",
    "        \"image/height\": _int64_feature(height),\n",
    "        \"image/filename\":_bytes_feature(bytes(filename, 'utf-8')),\n",
    "        # 'image/source_id': root.find(\"source\").text,\n",
    "        \"image/encodedrawdata\": _bytes_feature(image_string),\n",
    "        \"image/format\": _bytes_feature(bytes(filename.split(\".\")[-1], 'utf-8')),  # Assuming filename contains format\n",
    "        \"image/object/bbox/xmin\": _float_feature(xmin),\n",
    "        \"image/object/bbox/xmax\": _float_feature(xmax),\n",
    "        \"image/object/bbox/ymin\": _float_feature(ymin),\n",
    "        \"image/object/bbox/ymax\": _float_feature(ymax),\n",
    "        \"image/object/class/text\": _bytes_feature(bytes(label_text, 'utf-8')),\n",
    "        \"image/object/class/label\": _int64_feature(label),\n",
    "        \"image/object/class/single\": _int64_feature(label),  # Assuming single class per object\n",
    "        \"image/object/difficult\": _int64_feature(0),  # Difficult is 0\n",
    "        \"image/object/truncated\": _int64_feature(0),  # Truncated is 0\n",
    "        \"image/object/view\": _bytes_feature(bytes(\"Unspecified\", 'utf-8'))  # Assuming view is Unspecified for simplicity\n",
    "    }\n",
    "\n",
    "  return tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "\n",
    "  \"\"\"\n",
    "  Followed the article of Reading-Writing TFRecord for Images\n",
    "  https://www.tensorflow.org/tutorials/load_data/tfrecord\n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(image_paths,anno_list,anno_path, out_path):\n",
    "    # print('img :',image_paths)\n",
    "    # print('Op: ', out_path)\n",
    "    for img in image_paths:\n",
    "\n",
    "        img_name_ext = img.split(\"\\\\\")[-1]\n",
    "        img_name = img_name_ext.split('.')[0]\n",
    "\n",
    "        for anno in anno_list:\n",
    "            anno_name = anno.split(\".\")[0]\n",
    "    \n",
    "\n",
    "            if img_name == anno_name:\n",
    "                attr = parseXML(anno_path +\"\\\\\"+anno)\n",
    "\n",
    "                image_string = open(img, 'rb').read()\n",
    "\n",
    "                filename = attr[\"filename\"]\n",
    "                # print(filename)\n",
    "                # print(filename.split('.')[1])\n",
    "                width = attr[\"size\"][\"width\"]\n",
    "                height = attr[\"size\"][\"height\"]\n",
    "\n",
    "                xmin = attr[\"object\"][\"bndbox\"][\"xmin\"]\n",
    "                ymin = attr[\"object\"][\"bndbox\"][\"ymin\"]\n",
    "                xmax = attr[\"object\"][\"bndbox\"][\"xmax\"]\n",
    "                ymax = attr[\"object\"][\"bndbox\"][\"ymax\"]\n",
    "\n",
    "                # for obj in attr[\"object\"]:\n",
    "                #   print(obj)\n",
    "                #   xmin = obj[\"bndbox\"][\"xmin\"]\n",
    "                #   ymin = obj[\"bndbox\"][\"ymin\"]\n",
    "                #   xmax = obj[\"bndbox\"][\"xmax\"]\n",
    "                #   ymax = obj[\"bndbox\"][\"ymax\"]\n",
    "\n",
    "                label_text = attr[\"object\"][\"name\"]\n",
    "                label = image_labels.get(label_text, -1)  # Get label index or -1 if not found\n",
    "\n",
    "                image_string  = open((img), 'rb').read()\n",
    "                tf_example = get_image_example(image_string, width, height, filename, xmin, xmax, ymin, ymax, label, label_text)\n",
    "\n",
    "                file_name_ext = os.path.basename(img)\n",
    "                file_name = os.path.splitext(file_name_ext)[0]\n",
    "                output_filename = os.path.join(out_path, f'{file_name}.tfrecord')\n",
    "                with tf.io.TFRecordWriter(output_filename) as writer:\n",
    "                    writer.write(tf_example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert(train_img_list,train_anno_files_list ,train_anno_path , 'F:\\\\Coding\\\\cv_challenge\\\\TF_Records\\\\Train')\n",
    "convert(valid_img_list,valid_anno_files_list, valid_anno_path ,'F:\\\\Coding\\\\cv_challenge\\\\TF_Records\\\\Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfr_train = \"F:\\Coding\\cv_challenge\\TF_Records\\\\train\\scratches_10.tfrecord\"\n",
    "raw_image_dataset = tf.data.TFRecordDataset(filenames = [tfr_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_MapDataset element_spec={'image/object/bbox/xmax': SparseTensorSpec(TensorShape([None]), tf.float32), 'image/object/bbox/xmin': SparseTensorSpec(TensorShape([None]), tf.float32), 'image/object/bbox/ymax': SparseTensorSpec(TensorShape([None]), tf.float32), 'image/object/bbox/ymin': SparseTensorSpec(TensorShape([None]), tf.float32), 'image/object/class/label': SparseTensorSpec(TensorShape([None]), tf.int64), 'image/object/class/text': SparseTensorSpec(TensorShape([None]), tf.string), 'image/object/difficult': SparseTensorSpec(TensorShape([None]), tf.int64), 'image/object/truncated': SparseTensorSpec(TensorShape([None]), tf.int64), 'image/object/view': SparseTensorSpec(TensorShape([None]), tf.string), 'image/encodedrawdata': TensorSpec(shape=(), dtype=tf.string, name=None), 'image/filename': TensorSpec(shape=(), dtype=tf.string, name=None), 'image/format': TensorSpec(shape=(), dtype=tf.string, name=None), 'image/height': TensorSpec(shape=(), dtype=tf.int64, name=None), 'image/object/class/single': TensorSpec(shape=(), dtype=tf.int64, name=None), 'image/width': TensorSpec(shape=(), dtype=tf.int64, name=None)}>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_feature_description  = {\n",
    "      \"image/width\": tf.io.FixedLenFeature([], tf.int64),\n",
    "      \"image/height\": tf.io.FixedLenFeature([], tf.int64),\n",
    "      'image/filename': tf.io.FixedLenFeature([], tf.string),\n",
    "      # 'image/source_id': tf.io.FixedLenFeature([], tf.string),\n",
    "      'image/encodedrawdata': tf.io.FixedLenFeature([], tf.string),\n",
    "      'image/format': tf.io.FixedLenFeature([], tf.string),\n",
    "      'image/object/bbox/xmin': tf.io.VarLenFeature(tf.float32),\n",
    "      'image/object/bbox/xmax': tf.io.VarLenFeature(tf.float32),\n",
    "      'image/object/bbox/ymin': tf.io.VarLenFeature(tf.float32),\n",
    "      'image/object/bbox/ymax': tf.io.VarLenFeature(tf.float32),\n",
    "      'image/object/class/text': tf.io.VarLenFeature(tf.string),\n",
    "      'image/object/class/label': tf.io.VarLenFeature(tf.int64),\n",
    "      'image/object/class/single': tf.io.FixedLenFeature([], tf.int64),\n",
    "      'image/object/difficult': tf.io.VarLenFeature(tf.int64),\n",
    "      'image/object/truncated': tf.io.VarLenFeature(tf.int64),\n",
    "      'image/object/view': tf.io.VarLenFeature(tf.string)\n",
    "  }\n",
    "\n",
    "def _parse_image_function(example_proto):\n",
    "  # Parse the input tf.train.Example proto using the dictionary above.\n",
    "  return tf.io.parse_single_example(example_proto, image_feature_description )\n",
    "\n",
    "parsed_image_dataset = raw_image_dataset.map(_parse_image_function)\n",
    "parsed_image_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'scratches_10.jpg', shape=(), dtype=string)\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for image_features in parsed_image_dataset:\n",
    "    image_raw = image_features['image/encodedrawdata'].numpy()\n",
    "    print(image_features['image/filename'])\n",
    "    display.display(display.Image(data=image_raw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 - Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From f:\\Coding\\cv_challenge\\.venv\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From f:\\Coding\\cv_challenge\\.venv\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "Model: \"model\"\n",
      "____________________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   Trainable  \n",
      "============================================================================\n",
      " input_2 (InputLayer)        [(None, 200, 200, 3)]     0         Y          \n",
      "                                                                            \n",
      " xception (Functional)       (None, 7, 7, 2048)        2086148   N          \n",
      "                                                       0                    \n",
      "                                                                            \n",
      " batch_normalization_4 (Bat  (None, 7, 7, 2048)        8192      Y          \n",
      " chNormalization)                                                           \n",
      "                                                                            \n",
      " global_average_pooling2d (  (None, 2048)              0         Y          \n",
      " GlobalAveragePooling2D)                                                    \n",
      "                                                                            \n",
      " dense (Dense)               (None, 8)                 16392     Y          \n",
      "                                                                            \n",
      " dropout (Dropout)           (None, 8)                 0         Y          \n",
      "                                                                            \n",
      " dense_1 (Dense)             (None, 6)                 54        Y          \n",
      "                                                                            \n",
      "============================================================================\n",
      "Total params: 20886118 (79.67 MB)\n",
      "Trainable params: 20542 (80.24 KB)\n",
      "Non-trainable params: 20865576 (79.60 MB)\n",
      "____________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "image_height = 200\n",
    "image_width = 200\n",
    "n_color_channels = 3\n",
    "image_size = [image_height,image_width]\n",
    "batch_size = 64\n",
    "\n",
    "base_model = tf.keras.applications.Xception(input_shape=(*[image_height,image_width ],\n",
    "                                                         n_color_channels),\n",
    "                                                         include_top=False,\n",
    "                                                         weights=\"imagenet\")\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "inputs = keras.Input(shape=(image_height, image_width, n_color_channels))\n",
    "\n",
    "x = base_model(inputs, training=False)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = keras.layers.Dense(8)(x)\n",
    "x = keras.layers.Dropout(0.4)(x)  # Regularize with dropout\n",
    "outputs = keras.layers.Dense(6, activation='relu')(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "model.summary(show_trainable=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
